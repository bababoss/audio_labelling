{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'util'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1c0933d56526>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maudio_ops\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontrib_audio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext_to_char_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'util'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "from tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio\n",
    "\n",
    "from util.config import Config\n",
    "from util.text import text_to_char_array\n",
    "\n",
    "\n",
    "def read_csvs(csv_files):\n",
    "    source_data = None\n",
    "    for csv in csv_files:\n",
    "        file = pandas.read_csv(csv, encoding='utf-8', na_filter=False)\n",
    "        #FIXME: not cross-platform\n",
    "        csv_dir = os.path.dirname(os.path.abspath(csv))\n",
    "        file['wav_filename'] = file['wav_filename'].str.replace(r'(^[^/])', lambda m: os.path.join(csv_dir, m.group(1))) # pylint: disable=cell-var-from-loop\n",
    "        if source_data is None:\n",
    "            source_data = file\n",
    "        else:\n",
    "            source_data = source_data.append(file)\n",
    "    return source_data\n",
    "\n",
    "\n",
    "def samples_to_mfccs(samples, sample_rate):\n",
    "    spectrogram = contrib_audio.audio_spectrogram(samples,\n",
    "                                                  window_size=Config.audio_window_samples,\n",
    "                                                  stride=Config.audio_step_samples,\n",
    "                                                  magnitude_squared=True)\n",
    "    mfccs = contrib_audio.mfcc(spectrogram, sample_rate, dct_coefficient_count=Config.n_input)\n",
    "    mfccs = tf.reshape(mfccs, [-1, Config.n_input])\n",
    "\n",
    "    return mfccs, tf.shape(mfccs)[0]\n",
    "\n",
    "\n",
    "def audiofile_to_features(wav_filename):\n",
    "    samples = tf.read_file(wav_filename)\n",
    "    decoded = contrib_audio.decode_wav(samples, desired_channels=1)\n",
    "    features, features_len = samples_to_mfccs(decoded.audio, decoded.sample_rate)\n",
    "\n",
    "    return features, features_len\n",
    "\n",
    "\n",
    "def entry_to_features(wav_filename, transcript):\n",
    "    # https://bugs.python.org/issue32117\n",
    "    features, features_len = audiofile_to_features(wav_filename)\n",
    "    return features, features_len, tf.SparseTensor(*transcript)\n",
    "\n",
    "\n",
    "def to_sparse_tuple(sequence):\n",
    "    r\"\"\"Creates a sparse representention of ``sequence``.\n",
    "        Returns a tuple with (indices, values, shape)\n",
    "    \"\"\"\n",
    "    indices = np.asarray(list(zip([0]*len(sequence), range(len(sequence)))), dtype=np.int64)\n",
    "    shape = np.asarray([1, len(sequence)], dtype=np.int64)\n",
    "    return indices, sequence, shape\n",
    "\n",
    "\n",
    "def create_dataset(csvs, batch_size, cache_path=''):\n",
    "    df = read_csvs(csvs)\n",
    "    df.sort_values(by='wav_filesize', inplace=True)\n",
    "\n",
    "    # Convert to character index arrays\n",
    "    df['transcript'] = df['transcript'].apply(partial(text_to_char_array, alphabet=Config.alphabet))\n",
    "\n",
    "    def generate_values():\n",
    "        for _, row in df.iterrows():\n",
    "            yield row.wav_filename, to_sparse_tuple(row.transcript)\n",
    "\n",
    "    # Batching a dataset of 2D SparseTensors creates 3D batches, which fail\n",
    "    # when passed to tf.nn.ctc_loss, so we reshape them to remove the extra\n",
    "    # dimension here.\n",
    "    def sparse_reshape(sparse):\n",
    "        shape = sparse.dense_shape\n",
    "        return tf.sparse.reshape(sparse, [shape[0], shape[2]])\n",
    "\n",
    "    def batch_fn(features, features_len, transcripts):\n",
    "        features = tf.data.Dataset.zip((features, features_len))\n",
    "        features = features.padded_batch(batch_size,\n",
    "                                         padded_shapes=([None, Config.n_input], []))\n",
    "        transcripts = transcripts.batch(batch_size).map(sparse_reshape)\n",
    "        return tf.data.Dataset.zip((features, transcripts))\n",
    "\n",
    "    num_gpus = len(Config.available_devices)\n",
    "\n",
    "    dataset = (tf.data.Dataset.from_generator(generate_values,\n",
    "                                              output_types=(tf.string, (tf.int64, tf.int32, tf.int64)))\n",
    "                              .map(entry_to_features, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "                              .cache(cache_path)\n",
    "                              .window(batch_size, drop_remainder=True).flat_map(batch_fn)\n",
    "                              .prefetch(num_gpus))\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def secs_to_hours(secs):\n",
    "    hours, remainder = divmod(secs, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    return '%d:%02d:%02d' % (hours, minutes, seconds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.framework.python.ops import audio_ops\n",
    "\n",
    "# Wav file name\n",
    "wav_file = tf.placeholder(tf.string)\n",
    "\n",
    "# Read the wav file\n",
    "audio_binary = tf.read_file(wav_file)\n",
    "\n",
    "# Decode the wav mono into a 2D tensor with time in dimension 0\n",
    "# and channel along dimension 1\n",
    "waveform = audio_ops.decode_wav(audio_binary, file_format='wav', desired_channels=1)\n",
    "\n",
    "# Compute the spectrogram\n",
    "spectrogram = audio_ops.audio_spectrogram(\n",
    "        waveform.audio,\n",
    "        window_size=1024,\n",
    "        stride=64)\n",
    "\n",
    "# Custom brightness\n",
    "brightness = tf.placeholder(tf.float32, shape=[])\n",
    "mul = tf.multiply(spectrogram, brightness)\n",
    "\n",
    "# Normalize pixels\n",
    "min_const = tf.constant(255.)\n",
    "minimum =  tf.minimum(mul, min_const)\n",
    "\n",
    "# Expand dims so we get the proper shape\n",
    "expand_dims = tf.expand_dims(minimum, -1)\n",
    "\n",
    "# Resize the spectrogram to input size of the model\n",
    "resize = tf.image.resize_bilinear(expand_dims, [128, 128])\n",
    "\n",
    "# Remove the trailing dimension\n",
    "squeeze = tf.squeeze(resize, 0)\n",
    "\n",
    "# Tensorflow spectrogram has time along y axis and frequencies along x axis\n",
    "# so we fix that\n",
    "flip = tf.image.flip_left_right(squeeze)\n",
    "transpose = tf.image.transpose_image(flip)\n",
    "\n",
    "# Convert image to 3 channels, it's still a grayscale image however\n",
    "grayscale = tf.image.grayscale_to_rgb(transpose)\n",
    "\n",
    "# Cast to uint8 and encode as png\n",
    "cast = tf.cast(grayscale, tf.uint8)\n",
    "png = tf.image.encode_png(cast)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Run the computation graph and save the png encoded image to a file\n",
    "    image = sess.run(png, feed_dict={\n",
    "      wav_file: 'your_file.wav', brightness: 100})\n",
    "\n",
    "    with open('output.png', 'wb') as f:\n",
    "        f.write(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "almondaiEnv",
   "language": "python",
   "name": "almondaienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
